{
  "best_global_step": 2459,
  "best_metric": 0.9521267143037464,
  "best_model_checkpoint": "./cicids_llm_finetuned/checkpoint-2459",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2459,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02033760423022168,
      "grad_norm": 3.9395346641540527,
      "learning_rate": 1.9601464009760066e-05,
      "loss": 1.6275,
      "step": 50
    },
    {
      "epoch": 0.04067520846044336,
      "grad_norm": 1.535870909690857,
      "learning_rate": 1.9194794631964216e-05,
      "loss": 0.657,
      "step": 100
    },
    {
      "epoch": 0.06101281269066504,
      "grad_norm": 1.5724003314971924,
      "learning_rate": 1.8788125254168362e-05,
      "loss": 0.5426,
      "step": 150
    },
    {
      "epoch": 0.08135041692088672,
      "grad_norm": 1.545988917350769,
      "learning_rate": 1.8381455876372512e-05,
      "loss": 0.5625,
      "step": 200
    },
    {
      "epoch": 0.1016880211511084,
      "grad_norm": 1.1766293048858643,
      "learning_rate": 1.797478649857666e-05,
      "loss": 0.6246,
      "step": 250
    },
    {
      "epoch": 0.12202562538133008,
      "grad_norm": 1.1581180095672607,
      "learning_rate": 1.756811712078081e-05,
      "loss": 0.5582,
      "step": 300
    },
    {
      "epoch": 0.14236322961155176,
      "grad_norm": 2.773376226425171,
      "learning_rate": 1.7161447742984955e-05,
      "loss": 0.5922,
      "step": 350
    },
    {
      "epoch": 0.16270083384177345,
      "grad_norm": 3.2060844898223877,
      "learning_rate": 1.67547783651891e-05,
      "loss": 0.5075,
      "step": 400
    },
    {
      "epoch": 0.18303843807199513,
      "grad_norm": 1.3004887104034424,
      "learning_rate": 1.634810898739325e-05,
      "loss": 0.5072,
      "step": 450
    },
    {
      "epoch": 0.2033760423022168,
      "grad_norm": 1.5939606428146362,
      "learning_rate": 1.5941439609597397e-05,
      "loss": 0.4573,
      "step": 500
    },
    {
      "epoch": 0.22371364653243847,
      "grad_norm": 2.564393997192383,
      "learning_rate": 1.5534770231801547e-05,
      "loss": 0.458,
      "step": 550
    },
    {
      "epoch": 0.24405125076266015,
      "grad_norm": 1.7283717393875122,
      "learning_rate": 1.5128100854005694e-05,
      "loss": 0.4113,
      "step": 600
    },
    {
      "epoch": 0.26438885499288184,
      "grad_norm": 2.1803410053253174,
      "learning_rate": 1.4721431476209842e-05,
      "loss": 0.3905,
      "step": 650
    },
    {
      "epoch": 0.2847264592231035,
      "grad_norm": 2.582495927810669,
      "learning_rate": 1.431476209841399e-05,
      "loss": 0.3557,
      "step": 700
    },
    {
      "epoch": 0.3050640634533252,
      "grad_norm": 2.2759861946105957,
      "learning_rate": 1.3908092720618138e-05,
      "loss": 0.3427,
      "step": 750
    },
    {
      "epoch": 0.3254016676835469,
      "grad_norm": 1.906685709953308,
      "learning_rate": 1.3501423342822286e-05,
      "loss": 0.3249,
      "step": 800
    },
    {
      "epoch": 0.3457392719137686,
      "grad_norm": 3.147498369216919,
      "learning_rate": 1.3094753965026434e-05,
      "loss": 0.3317,
      "step": 850
    },
    {
      "epoch": 0.36607687614399026,
      "grad_norm": 2.9652936458587646,
      "learning_rate": 1.2688084587230582e-05,
      "loss": 0.3414,
      "step": 900
    },
    {
      "epoch": 0.38641448037421194,
      "grad_norm": 1.4998754262924194,
      "learning_rate": 1.228141520943473e-05,
      "loss": 0.3522,
      "step": 950
    },
    {
      "epoch": 0.4067520846044336,
      "grad_norm": 3.6894919872283936,
      "learning_rate": 1.1874745831638879e-05,
      "loss": 0.2499,
      "step": 1000
    },
    {
      "epoch": 0.42708968883465526,
      "grad_norm": 4.532608509063721,
      "learning_rate": 1.1468076453843027e-05,
      "loss": 0.3336,
      "step": 1050
    },
    {
      "epoch": 0.44742729306487694,
      "grad_norm": 3.8784048557281494,
      "learning_rate": 1.1061407076047175e-05,
      "loss": 0.2928,
      "step": 1100
    },
    {
      "epoch": 0.4677648972950986,
      "grad_norm": 3.7665789127349854,
      "learning_rate": 1.0654737698251323e-05,
      "loss": 0.2741,
      "step": 1150
    },
    {
      "epoch": 0.4881025015253203,
      "grad_norm": 2.581315040588379,
      "learning_rate": 1.0248068320455471e-05,
      "loss": 0.3237,
      "step": 1200
    },
    {
      "epoch": 0.508440105755542,
      "grad_norm": 2.672353506088257,
      "learning_rate": 9.84139894265962e-06,
      "loss": 0.2622,
      "step": 1250
    },
    {
      "epoch": 0.5287777099857637,
      "grad_norm": 1.9155486822128296,
      "learning_rate": 9.434729564863766e-06,
      "loss": 0.2617,
      "step": 1300
    },
    {
      "epoch": 0.5491153142159854,
      "grad_norm": 4.457020282745361,
      "learning_rate": 9.028060187067914e-06,
      "loss": 0.292,
      "step": 1350
    },
    {
      "epoch": 0.569452918446207,
      "grad_norm": 1.294318675994873,
      "learning_rate": 8.621390809272062e-06,
      "loss": 0.2319,
      "step": 1400
    },
    {
      "epoch": 0.5897905226764287,
      "grad_norm": 5.3373517990112305,
      "learning_rate": 8.21472143147621e-06,
      "loss": 0.2314,
      "step": 1450
    },
    {
      "epoch": 0.6101281269066504,
      "grad_norm": 6.00691032409668,
      "learning_rate": 7.808052053680358e-06,
      "loss": 0.2985,
      "step": 1500
    },
    {
      "epoch": 0.6304657311368721,
      "grad_norm": 7.36285400390625,
      "learning_rate": 7.4013826758845065e-06,
      "loss": 0.2301,
      "step": 1550
    },
    {
      "epoch": 0.6508033353670938,
      "grad_norm": 6.3410186767578125,
      "learning_rate": 6.994713298088655e-06,
      "loss": 0.2088,
      "step": 1600
    },
    {
      "epoch": 0.6711409395973155,
      "grad_norm": 1.616943359375,
      "learning_rate": 6.588043920292803e-06,
      "loss": 0.1884,
      "step": 1650
    },
    {
      "epoch": 0.6914785438275372,
      "grad_norm": 4.213325023651123,
      "learning_rate": 6.181374542496951e-06,
      "loss": 0.2044,
      "step": 1700
    },
    {
      "epoch": 0.7118161480577588,
      "grad_norm": 1.1073552370071411,
      "learning_rate": 5.774705164701099e-06,
      "loss": 0.2192,
      "step": 1750
    },
    {
      "epoch": 0.7321537522879805,
      "grad_norm": 5.33766508102417,
      "learning_rate": 5.368035786905247e-06,
      "loss": 0.2509,
      "step": 1800
    },
    {
      "epoch": 0.7524913565182022,
      "grad_norm": 5.207521915435791,
      "learning_rate": 4.961366409109394e-06,
      "loss": 0.2171,
      "step": 1850
    },
    {
      "epoch": 0.7728289607484239,
      "grad_norm": 1.236748218536377,
      "learning_rate": 4.5546970313135425e-06,
      "loss": 0.2275,
      "step": 1900
    },
    {
      "epoch": 0.7931665649786455,
      "grad_norm": 2.494555711746216,
      "learning_rate": 4.148027653517691e-06,
      "loss": 0.2217,
      "step": 1950
    },
    {
      "epoch": 0.8135041692088671,
      "grad_norm": 3.286273241043091,
      "learning_rate": 3.7413582757218388e-06,
      "loss": 0.2244,
      "step": 2000
    },
    {
      "epoch": 0.8338417734390888,
      "grad_norm": 3.2600886821746826,
      "learning_rate": 3.334688897925987e-06,
      "loss": 0.1915,
      "step": 2050
    },
    {
      "epoch": 0.8541793776693105,
      "grad_norm": 5.066918849945068,
      "learning_rate": 2.928019520130134e-06,
      "loss": 0.2398,
      "step": 2100
    },
    {
      "epoch": 0.8745169818995322,
      "grad_norm": 1.4363219738006592,
      "learning_rate": 2.5213501423342823e-06,
      "loss": 0.2091,
      "step": 2150
    },
    {
      "epoch": 0.8948545861297539,
      "grad_norm": 3.38737416267395,
      "learning_rate": 2.1146807645384304e-06,
      "loss": 0.1756,
      "step": 2200
    },
    {
      "epoch": 0.9151921903599756,
      "grad_norm": 3.8566136360168457,
      "learning_rate": 1.7080113867425785e-06,
      "loss": 0.198,
      "step": 2250
    },
    {
      "epoch": 0.9355297945901973,
      "grad_norm": 5.591516971588135,
      "learning_rate": 1.3013420089467262e-06,
      "loss": 0.2159,
      "step": 2300
    },
    {
      "epoch": 0.9558673988204189,
      "grad_norm": 2.5197396278381348,
      "learning_rate": 8.946726311508744e-07,
      "loss": 0.2286,
      "step": 2350
    },
    {
      "epoch": 0.9762050030506406,
      "grad_norm": 7.36611795425415,
      "learning_rate": 4.880032533550224e-07,
      "loss": 0.1985,
      "step": 2400
    },
    {
      "epoch": 0.9965426072808623,
      "grad_norm": 6.470397472381592,
      "learning_rate": 8.133387555917039e-08,
      "loss": 0.2044,
      "step": 2450
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9590146221998127,
      "eval_f1_weighted": 0.9521267143037464,
      "eval_loss": 0.1854085475206375,
      "eval_runtime": 55.2304,
      "eval_samples_per_second": 251.365,
      "eval_steps_per_second": 7.858,
      "step": 2459
    }
  ],
  "logging_steps": 50,
  "max_steps": 2459,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5363639055083520.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
